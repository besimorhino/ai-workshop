{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN97lSk5UZbZ04xQjCaFd5a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7EtkhWv0jpRh","executionInfo":{"status":"ok","timestamp":1758223771621,"user_tz":240,"elapsed":17831,"user":{"displayName":"Michael Douglas","userId":"18175190374739640617"}}},"outputs":[],"source":["# Cell 1: Install dependencies\n","!pip install -q transformers torchaudio librosa matplotlib scikit-learn"]},{"cell_type":"code","source":["# Cell 2: Imports\n","import torch\n","import torchaudio\n","import librosa\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from transformers import Wav2Vec2Model, Wav2Vec2Processor\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.decomposition import PCA\n","from IPython.display import Audio, display"],"metadata":{"id":"N1XXTTofljS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell 3: Load Wav2Vec2 pre-trained model\n","processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","model.eval()"],"metadata":{"id":"kq5H9GCnln0O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell 4: Upload audio files (or use samples)\n","from google.colab import files\n","uploaded = files.upload()\n","\n","# Load and resample to 16kHz mono\n","waveforms = []\n","file_names = []\n","\n","for fn in uploaded.keys():\n","    waveform, sr = torchaudio.load(fn)\n","    waveform = waveform.mean(dim=0).unsqueeze(0)  # convert to mono\n","    if sr != 16000:\n","        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n","        waveform = resampler(waveform)\n","    waveforms.append(waveform)\n","    file_names.append(fn)"],"metadata":{"id":"ctZ2V762lqCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell 5: Listen to audio\n","for i, fn in enumerate(file_names):\n","    print(f\"Audio {i+1}: {fn}\")\n","    display(Audio(waveforms[i].squeeze().numpy(), rate=16000))\n"],"metadata":{"id":"Aadic5HElsUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell 6: Generate embeddings\n","embeddings = []\n","with torch.no_grad():\n","    for waveform in waveforms:\n","        inputs = processor(waveform.squeeze(), sampling_rate=16000, return_tensors=\"pt\")\n","        outputs = model(**inputs)\n","        # Take mean of last hidden state as embedding\n","        emb = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n","        embeddings.append(emb)\n","\n","embeddings = np.stack(embeddings)\n"],"metadata":{"id":"XrcXebmglvG7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell 7: Compute cosine similarity\n","sim = cosine_similarity(embeddings)\n","import pandas as pd\n","df = pd.DataFrame(sim, index=file_names, columns=file_names)\n","df.style.background_gradient(cmap='Blues')\n"],"metadata":{"id":"HnurBYvdlxAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell 8: Visualize in 2D\n","pca = PCA(n_components=2)\n","reduced = pca.fit_transform(embeddings)\n","\n","plt.figure(figsize=(8, 6))\n","for i, fn in enumerate(file_names):\n","    x, y = reduced[i]\n","    plt.scatter(x, y)\n","    plt.text(x + 0.01, y + 0.01, fn, fontsize=9)\n","plt.title(\"Audio Embeddings in 2D Space\")\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"MqC84nCFlylR"},"execution_count":null,"outputs":[]}]}